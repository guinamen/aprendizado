%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% How to use writeLaTeX: 
%
% You edit the source code here on the left, and the preview on the
% right shows you the result within a few seconds.
%
% Bookmark this page and share the URL with your co-authors. They can
% edit at the same time!
%
% You can upload figures, bibliographies, custom classes and
% styles using the files menu.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}

\usepackage[portuguese]{babel} 
\usepackage[utf8]{inputenc}
\usepackage{parskip}
\usepackage{enumitem}
\usepackage{amsmath}

\newlist{questions}{enumerate}{2}
\setlist[questions,1]{label=P\arabic*.,ref=P\arabic*}
\setlist[questions,2]{label=(\alph*),ref=\thequestionsi(\alph*)}

\newlist{metrics}{enumerate}{2}
\setlist[metrics,1]{label=M\arabic*.,ref=M\arabic*}
\setlist[metrics,2]{label=(\alph*),ref=\thequestionsi(\alph*)}

\newlist{goal}{enumerate}{2}
\setlist[goal,1]{label=Meta\arabic*.,ref=Meta\arabic*}
\setlist[goal,2]{label=(\alph*),ref=\thequestionsi(\alph*)}
     
\sloppy

\title{Trabalho de Aprendizado Descritivo\\ Pipeline Descritvo}

\author{Guilherme Namen Pimenta\inst{1} }


\address{Departamento de Ciência da Computação \\ Universidade Federal de Minas Gerais
  (UFMG)\\
  Belo Horizonte -- MG -- Brasil
}

\begin{document} 

\maketitle

%%\begin{abstract}
  
%%\end{abstract}
     
\begin{resumo} 
O presente trabalho tem como obejtivo apresentar um sistema de descoberta de conhecimento baseado na arquitetura de duto e filtros para descrever o espaço urbano da Capital Mineira Belo Horizonte. Foi verificado que as regiões mais distantes do centro possuem características de moradias com a maioria casas. A regiões mais próximas possuem características mistas de moradia e comércio local. Foi indentificado padrões de relevância como a presença de vagas de garagem próximo a imóveis comerciais de alto acabamento. E por fim foi realizado um pequeno experimento para análisar o processo social de gentrificação dentro da Regional Centro-Sul, onde foram encontrados os imóveis que estariam mais susceptíveis ao interesse do mercado imobiliário de alto padrão. 
\end{resumo}


\section{Introdução}

Os impressionantes avanços em tecnologia de aprendizado de máquina estão cada vez mais presentes no cotidiano das pessoas \cite{doshi2017towards}, frequentemente superando o desempenho humano em algumas tarefas \cite{silver2016mastering}. No entanto, muitas ferramentas de aprendizado de máquina não permitem a auditoria de seus métodos, pois não produzem regras plenamente interpretáveis, dificultando o processo de verificação pelos administradores. Neste trabalho, o termo interpretação é definido como a capacidade de gerar termos plenamente compreensíveis por humanos. Para uma definição mais completa e discussão mais profunda, recomenda-se o trabalho de Doshi-Velez et al \cite{doshi2017towards}. 

Uma forma de gerar regras compreensíveis é utilizar técnicas de mineração de dados \cite{zaki2014data}, que possuem a capacidade de processar grandes quantidades de dados e gerar modelos descritivos de interesse, facilmente interpretáveis. 

Atualmente, há uma vasta gama de algoritmos e ferramentas \cite{mikut2011data} de mineração de dados, desenvolvidos ao longo dos últimos 25 anos \cite{luna2019frequent}. Embora esses algoritmos gerem muitos resultados, nem todos são de interesse, devido ao espaço de busca que cresce exponencialmente \cite{zaki2014data}. Dada a quantidade de informações geradas e a diversidade de algoritmos propostos, este trabalho tem como objetivo adaptar a arquitetura de dutos e filtros de descoberta de conhecimento em banco de dados \cite{nwagu2017knowledge}, utilizando um conjunto mínimo de algoritmos de mineração de dados.

\section{Desenvolvimento}

Para guiar o desenvolvimento do pipeline de algoritmos de mineração de dados, foi escolhido o Princípio da Descrição de Comprimento Mínimo (DCM) da mesma forma que foi utilizado na tese de Proença \cite{proencca2021robust}.  O princípio é definido como: "DCM é baseado no seguinte pensamento: qualquer regularidade em um certo conjunto de dados pode ser utilizada para compressão de dados, para descrevê-lo usando menos símbolos que o necessário para descrever os dados literalmente" \cite{grunwald2007minimum}. Pode-se assemelhar este conceito com o processo de compressão de dados  \cite{proencca2021robust}.

Para o desenvolvimento do trabalho foi utilizada a metodologia Goal Question Metric (GQM) \cite{caldiera1994goal}, metodologia muito utilizada no campo da Engenharia de Software \cite{sommerville2011software}. 

Sendo assim a meta é: desenvolver um sistema em arquitetura de dutos e filtros (pipeline) para melhor descrever os dados de uma base utilizando o princípio DCM. 

Os questionamentos são:
\begin{questions}
        \item Quais os algoritmos de mineração de dados são úteis para descrever uma base de dados?
        \item Quais informações eles podem gerar?
        \item Qual é a melhor sequência de algoritmos para descrever os dados e formar a arquitetura de dutos?
\end{questions}

As métricas são: 
\begin{metrics}
        \item Número de resultados produzidos pelo algoritmo.
        \item Hiper parâmetros dos algoritmos.
        \item Qualidade do resultado.
\end{metrics}
\section{Descrição dos dados}
Para este trabalho foi utilizado um base de dados dos imóveis da Capital Mineira Belo Horizonte, os dados encontram-se no Portal de Dados Abertos da Prefeitura de Belo Horizonte. A escolha desta base deve-se ao seu tamanho e à sua importância para as Políticas de Uso e Ocupação do Solo do município e a facilidade para comprovar os resultados, uma vez que os autores residem nesta localidade. 

O Portal de Dados Abertos possui a série histórica dos dados imobiliários de Belo Horizonte, divididos pelas regionais, que se constitui de uma divisão geográfica baseada em critérios únicos de cada regional. Ao todo a capital está dividida nas seguintes nove regionais:
%% tabela

\begin{table}
    \centering
    \begin{tabular}{cccc}
Regional & População\footnote{IBGE Censo 2010} & Área (km²) & Bairros\\
\hline
Barreiro & 282.156 & 53,6 & 73\\
Centro-Sul & 282.286 & 31,85 & 49\\
Leste & 228.986 & 27,98 & 47\\
Nordeste & 281.507 & 39,46 & 69\\
Noroeste & 271.143 & 30,17 & 52\\
Norte & 214.967 & 32,67 & 48\\
Oeste & 316.908 & 36,06 & 67\\
Pampulha & 266.859 & 51,21 & 63\\
Venda Nova & 230.339 & 29,27 & 44\\
\hline
\hline
TOTAL & 2.375.151 & 332,27 & 487\footnote{Alguns bairros estão em mais de uma regional}\\

    \end{tabular}
    \caption{Regionais}
    \label{tab:regionais}
\end{table}
Ao todo foram coletados 876.817 registros imobiliários publicados na data de  03/06/2024 com as seguintes características: Nome da regional, índice cadastral, frequência da coleta de lixo, existência de meio fio, existência de via pavimentada, existência de arborização, existência de galeria pluvial, existência de iluminação pública, existência de rede de esgoto, existência de rede de água, existência de rede telefônica, área do terreno,  área construtiva, tipo de construção, tipo de ocupação, padrão de acabamento do imóvel, quantidade de economias, fração ideal, tipo do logradouro, nome do logradouro, número do imóvel, CEP, zona homogenia (classificação do imóvel para critérios de cobrança de imposto), tipologia do imóvel, geometria do terreno, coordenadas de latitude e longitude do centroide da geometria do terreno.

Ao analisar a área construída dos imóveis, foi constado que, ela varia muito em função dos tipos de imóveis. Sendo observado a existência de muitos valores fora do padrão (outliers). Sendo assim, uma nova dimensão binária foi adicionada aos dados, classificando-os em outliers, em relação ao tipo construtivo. Caso estejam fora do intervalo $I$ definido abaixo. Sendo $IQR$ o valor interquartil e $q_n$ o valor do enésimo quartil $I = \left[ q_{0,25} - 1.5IQR;q_{0,75} + 1.5IQR  \right]$ . Ao todo foram classificados imóveis 42.849 como sendo outliers e 833.968 não. 

\section{Arquitetura de Dutos e Filtros}

\subsection{Primeira Fase: Seleção}


Na primeira fase da arquitetura os dados coletados são limpos e corrigidos e armazenados em um banco de dados, seguindo as seguintes atividades. Valores nulos numéricos foram substituídos pela média dos imóvies próximo. Dados nulos referentes à meio fio, pavimentação e iluminação foram corrigido por imagens do Google Street View. E endereços fora de Belo Horizonte foram removidos.

\subsection{Segunda Fase: Pré-Processamento}

A ferramenta GritBot da empresa RuleQuest Research é uma ferramenta automática que detecta anomalias nos dados, sendo considerada uma precursora dos algoritmos de mineração de dados. A publicação de Bay e Schwabacher \cite{bay2003mining} propuseram uma abordagem focada no desempenho para grandes bases de dados e realiza uma análise comparativa com o GritBot, como conclusão, afirmam que a ferramenta apresenta bons resultados para bases não muito grandes. Sendo assim, ela foi utilizada nos dados de cada regional de forma separada para gerar uma lista de registros anômalos. 

Uma análise superficial dos dados verificou que a regional Centro-Sul possui o maior número de registros com a maior intensidade de coleta de lixo e com a maioria dos imóveis de padrão de acabamento 5, o mais alto.

\subsection{Tereciera Fase: Transformação dos Dados}

Para um melhor desempenho dos algoritmos de mineração de dados, a base de dados foi segmentada em nove bases referente aos imóvies de cada regional. As primeiras aplicações de mineração de dados, processavam as informações já transformadas em bancos transacionais. Para os dados geográficos as bases não têm esta propriedade. Sendo assim foi realizado uma avaliação de como transformar o banco de dados em um banco de transações.

\subsubsection{Transações}
Para analisar o espaço urbano de Belo Horizonte através dos algoritmos de mineração de itemsets frequentes, inicialmente deve-se escolher uma forma de agrupar os itens em transações. Para esse estudo foi utilizado o agrupador do CEP, que é o código postal dos Correios do Brasil. Ele é utilizado para facilitar o encaminhamento e a entrega das correspondências aos destinatários. O código está relacionado indiretamente pelo uso e ocupação do espaço urbano, pois quanto mais correspondências um local possui, mais o logradouro terá CEPs distintos. Por exemplo, condomínios muito grandes possuem um código próprio. Ele também possui a vantagem de estar relacionado ao bairro, pois grandes avenidas ou ruas podem estar em bairros diferentes e apresentar vários códigos distintos para cada bairro. 

 A base de dados possui localidades que não têm CEP (valor do campo igual a zero), nestes casos o agrupamento utilizado foi o nome e tipo do logradouro e o resultado concatenado aos demais.
 
 \subsubsection{Itens}
 Para definir o conjunto dos itens, inicialmente, foi utilizado o produto cartesiano entre os valores das colunas de qualidade do acabamento do imóvel, o tipo construtivo e se a área construída é um outlier, totalizando 101 itens. Os tipos construtivos possuem a informação do uso do imóvel sendo residencial ou não, sendo assim não há necessidade de utilizar a coluna do tipo de ocupação do imóvel.

 \subsubsection{Utilidade}
 Os imóveis do espaço urbano podem variar muito em função da área construída, não somente pelos tipos e pela qualidade de acabamento. Como a área é um valor numérico em metros quadrados, ela foi adotada como valor e utilidade. O problema é que existem terrenos em que a área construída é zero. Para tal será feita duas abordagens, uma em que os terrenos sem construção são removidos da análise dos algoritmos, e uma abordagem em que será utilizada a área do terreno sem imóvel como uma utilidade negativa. Como o objetivo é caracterizar as regiões geográficas pelo uso e ocupação faz sentido um terreno sem construções ter uma utilidade negativa.

 \subsection{Quarta Fase: Mineração de Dados}
 Para minerar os dados a ferramenta SPMF \cite{SPMF} foi utilizada pois apresenta uma grande quantidade de algoritmos de mineração de dados com os mais diversos propósitos. Para descoberta de subgrupos a ferramenta Cortana Subgroup Discovery \cite{meeng2011flexible} por prover deversas formas de configuração de descoberta de subgrupos.
 \subsubsection{Análise dos Itensets frequentes}
 Para descrever as regiões geográficas foi escolhido os algoritmos de mineração de itens frequentes pela sua capacidade interpretativa. O trabalho de Luna et al\cite{luna2019frequent}, traz um excelente retrospectiva. Com base no princípio DCM foram filtrados apenas algoritmos mineração de itemset fechados. Um itemset é considerado fechado se e somente se não existe nenhum super conjunto com o mesmo suporte \cite{lucchese2004mining}. A partir deles é possível gerar todos os itemsets com suporte maior ou igual ao limite informado, porém sem a informação do suporte. Para a arquitetura, foi escolhido o algoritmo FPClose \cite{grahne2005fast} pela eficiência em gerar apenas candidatos válidos. O suporte mínimo de 40\% foi utilizado para reduzir ao máximo o número de resultados. Em todas as execuções nenhum imóvel com metragem fora do padrão foi encontrado.
\paragraph{Resultados}
Os resultados demonstram muito bem que as regionais mais distantes do Centro da cidade têm a característica de fornecer moradias em sua maioria casas de padrões variando do 2 ao 3. Neste grupo destaca-se a regional Pampulha que apresenta casas com o padrão de acabamento 4. As regionais próximas ao Centro apresentam um padrão misto de moradias de casas e barracões com comércio local. Neste grupo destaca-se a regional Leste que apresentou o maior número de itemsets fechados, com uma grande variação tanto no tipo quanto na qualidade do acabamento dos imóveis. A regional Centro-Sul apresentou todos os itemsets com apenas um item, o que pode ser uma característica do planejamento urbano inicial da Capital Mineira, em que as ruas foram muito bem definidas e segmentadas. A regional possui muitos imóveis de qualidade de acabamento alto e lojas com grandes áreas construídas, o que vai de encontro com a alta intensidade de coleta de lixo, indicando uma intensa atividade comercial. A dinâmica da Capital não foge à dinâmica das grandes cidades em que os subúrbios fornecem moradias e a região central fornece trabalho, o que o algoritmo traz de novo é que as regiões mais próximas ao centro possuem uma quantidade significativa de comércio local e de moradias de baixo padrão construtivo, ao contrário das regiões mais distantes, que predominam apenas casas como moradia. 

\subsubsection{Análise dos itemsets estatisticamente relevantes}
O tabalho de Webb e Vreeken \cite{webb2013efficient} propõe um novo algoritmo, chamado OPUS Miner, para encontrar associações interessantes em dados. Ao contrário de métodos tradicionais que retornam muitos padrões redundantes, o OPUS Miner visa encontrar um conjunto menor de associações "autossuficientes" que são mais propensas a serem úteis para o usuário. 

 Uma Associações Autossuficiente é uma associação é considerada autossuficiente se for: 
\begin{itemize}
    \item Produtiva: Seus itens ocorrem juntos com mais frequência do que o esperado se fossem independentes.
    \item Não Redundante: Sua frequência não pode ser explicada pela frequência de seus subconjuntos. 
    \item Independentemente Produtiva: Sua frequência não pode ser explicada pela frequência de seus superconjuntos. 
\end{itemize}

O OPUS Miner é um algoritmo branch-and-bound que explora o espaço de busca de itemsets e usa limites eficientes para podar o espaço de busca e acelerar a descoberta. As suas limitações são: dificuldade em buscar itemsets muito grandes devido ao rigor estatístico e considera apenas associações positivas. Para análise o algoritmo foi configurado para 10 regras de associação, com os parâmetros check independency (filter), search by lift \cite{wiki:lift}, check redundancy e correction for multicompare como verdadeiros. A métrica de lift foi utilizada para que itemsets de baixo suporte não sejam penalizados, pois caso contrário o resultado seria muito próximo ao resultado do algoritmo anterior.

\paragraph{Resultados}
Este algoritmo demonstrou um grande poder para detectar padrões em imóveis de alta qualidade de acabamento, tanto moradias quanto comerciais. Estes imóveis sofrem grandes penalizações ao serem analisados por algoritmos de análise de suporte porque são muito infrequentes. Em todas as regionais apresentaram itemsets com garagem e salas, demonstrando a importância de se ter estacionamento próximo aos centros de prestação de serviços. Uma outra questão é que imóveis com mais área construtiva tendem a estarem no mesmo CEP que os imóveis de mesmo padrão construtivo com padrão de acabamento igual ou superior. A regional Centro-Sul destaca-se apresentando 82 CEPs com sala padrão de acabamento 5 e garagem comercial de padrão de acabamento 5. Demonstrando a tendência de que os imóveis comerciais de alto padrão devem ter o serviço de garagem próximo por padrão. Os resultados também mostram uma tendência, nas regionais mais distantes do centro, de se adaptar imóveis de moradia para o comércio quando eles estão próximos aos imóveis comerciais.

\subsubsection{Análise da utilidade em metros quadrados construídos}
Ao analisar os imóveis, somente a frequência não é suficiente devido às características dos edifícios. Algumas regiões podem ter poucos deles, abrigando uma quantidade muito grande de pessoas, tanto com o intuito de moradia como comércio. Sendo assim o algoritmo FHM Freq, que é uma adaptação do algoritmo FHM \cite{fournier2014fhm} para limitar os itemsets pelo suporte mínimo. No experimento foi utilizada a seguinte configuração: utilidade mínima como 1 Km² e no mínimo 30\% de suporte.
\paragraph{Resultados}
Ao cruzar a informação da área construída com o suporte, obtém-se uma análise detalhada dos imóveis. A análise é semelhante ao algoritmo FPMax, mas revela a presença de comércio local nas regionais Barreiro, Nordeste, Norte e Venda Nova, devido à distância da regional Centro-Sul, que possui grandes centros comerciais.

A regional Oeste apresenta uma grande quantidade de apartamentos com acabamento 3, totalizando mais de 4 km² construídos, divergindo da análise anterior que sugeriu baixa verticalização. Acredita-se que a edificação da região se concentrou em predios de muitos andares com perfil de moradia, pois a regional abriga a maior população da capital. A regional Pampulha destaca-se por suas casas de acabamento 4, totalizando 1,2 km² em 779 CEPs.

A regional Noroeste possui uma grande área construída destinada a galpões, indicando boas características para o setor logístico, como rodovias e avenidas amplas. A regional Leste apresenta um alto contraste, evidenciado pelos registros de apartamentos com acabamento 3 próximos a casas de acabamento 2 e 3. O baixo suporte do primeiro item pode indicar um grande potencial de verticalização sobre casas.

A regional Centro-Sul foi a única a apresentar itens com área construída muito acima do padrão, especialmente lojas com acabamento 3 e apartamentos com acabamento 3 e 4. A região demonstra intensa edificação tanto vertical quanto horizontal. A associação de casas e apartamentos indica que ainda há potencial para a criação de mais edifícios na região.

 \subsubsection{Análise da utilidade negativa}
Para avaliar o impácto da existência de lotes vagos em cada regional, o algoritmo FHN \cite{fournier2014fhn} foi utilizado de duas formas, um com a mesma base de transações do algortimo anterior e uma base com item de lote vago com a utilidade negativa. Para analisar todas as bases a utilidade mínima foi de 1Km².
Nesta abordagem o que foi avaliado foram o número de itemsets resultantes das duas execuções, caso o impacto de se ter muitos lotes vagos seja significativo o número de itemset da segunda execução será menor.

\paragraph{Resultados}
Nesta abordagem foi verificado que somente as regionais Pampulha e Norte tiveram um impacto negativo, indicando que elas possuem baixo número de imóvies com pouca área construída, provavelmente baixo indice de edificações e com um grande área de terrenos vagos. Acredita-se que isto se deve à distância do centro da cidade e baixo índice de cornurbação \cite{wiki:cornubacao}.

\subsubsection{Análise de subgrupo}
Para uma abordagem mais profunda dos imóveis da Capital, foi escolhido a análise do tema social de gentrificação \cite{dos2019sapucai, solla2019resistencia, andrade2020urban}. Os estudos citados levam em cosideração regiões urbanas limitadas a bairros, para esta análise o objetivo é levantar os imóveis que podem estar em situação social vulnerável dentro de uma região urbana mais extensa, no caso a regional. Para avaliar esta questão, foi utilizado a abordagem de descoberta de subgrupos \cite{atzmueller2015subgroup}.Basicamente ela é uma técnica descritiva que gera subgrupos de um banco de dados que possuem elementos que demonstram compartamentos interessantes em relação a uma valor alvo. Para tal o valor alvo escolhido foi o padrão de acabamento 5, o mais alto. A partir do valor alvo apenas a regional Centro-Sul foi escolhida, pois ela contém a grande maioria dos imóveis de alto acabamento, diversidade de tipos construtivos e ocupação.

\paragraph{Criação do Banco de Dados}
Para a análise de subgrupo um novo banco de dados foi criado. Apenas os imóveis destinados a moradia que não fossem uma vaga de garagem foram escolhidos. Desta forma eles foram agrupados pelas coordenadas geográficas do centroide do terreno. Sendo assim as informações de área construída foi totalizada e para o caso de edifícios ela foi divida pelo total de economias para obter a área construída média de cada apartamento, a área do terreno, o tipo construtivo e o padrão de acabamento foram sumarizados pelo valor máximo. Ao todo foram coletados 14.956 registros contendo latitude, longitude, área do terreno, área construída, o tipo construtivo e o padrão de acabamento. O banco contém 1.567 registros de imóveis com padrão 5.

\paragraph{Configuração do Cortana}
Para configurar o Cortana foi escolhida a variável padrão de acabamento com o valor alvo P5; com a medidade de qualidade de Jaccard com valor mínimo de 0,2; com a profundidde 5; estratégia best first; estratégia numérica best
\paragraph{Resultados}
Foram gerados 2993 subgrupos todos eles com a medida de qualidade variando de 0,44 à 0,2. Sendo assim iremos analisar o primeiro subgrupo.
\begin{table}[ht]
\centering
\label{table:sub}
\begin{tabular}{cccc}
 Cobertura & Qualidade & Probabilidade & Positivos  \\
 2209 & 0,44 & 0,52  &  1.159  \\
\end{tabular}
\caption{Primeiro Sub Grupo}
\end{table}

\begin{gather*}
423.0 <= Area \quad Construida <= 3444.27  \quad \land \\ Latitude <= 614227.2 \land Area \quad Terreno >= 441.0  \land Longitude <= 7796076.5
\end{gather*}
\begin{table}[ht]
\centering
\label{table:sub-aca}
\begin{tabular}{cc}
 Padrão Acabamento & Total  \\
 1 e 2 & 24 \\
 3 & 276 \\
 4 e 5 & 1.909 \\
\end{tabular}
\caption{Total de registros por acabamento}
\end{table}
Ao filtramos os dados originais verificamos os seguintes logradouros com pontencial foco de gentrificação: rua Cervantes, avenida Nossa Senhora do Carmo e rua Claudio Manuel. A vantagem da análise de subgrupo é que o processo social da gentrificação pode ser analisado em diversos níveis não somente entre os extremos como foi feita esta análise, e em localidades geralmente associados a imóveis de alto padrão.

\subsection{Quarta Fase: Conhecimento}
As fases da arquitetura demonstraram ser capazes de extrair conhecimento mais amplos até os mais detalhados, como por exemplo encontrar padrões de imóveis que podem estar mais sujeitos a certos processos sociais. Esta fase constitui-se do relatório final contendo todo o conhecimento gerado.

\section{Respostas}
\paragraph{P1} Os algoritmos de mineração de dados mais úteis para descrever uma base de dados foram: FPMax, OpusMiner, FHM Freq, FHN e Descoberta de Subgrupo. Esta sequência de algoritmos descrevem os dados de forma mais genérica à mais específica. Com um mínimo de hiper parâmetros e um mínimo de resultados, todos gerarm resultados de extrema importância para descrever o espaço urbano da Capital Mineira.
\paragraph{P2} Eles conseguem em sequência gerarem um conjunto de informações mais genéricas até as mais específicas.
\paragraph{P3} A melhor sequência de execução dos algoritmos foi a apresentada no trabalho, a grande importância do trabalho foi que para utilizar o algoritmo de descoberta de subgrupos de forma mais eficiênte, a melhor forma é compreender a base de dados para segmentar muito bem os registros que serão processados. Diminuído o tempo de execução e melhorando a qualidade do resultado.

\section{Conclusão}
A arquitetura de dutos e filtros proposta, é simples, sequencial e realiza a análise de um grão mais grosso ao mais fino, e em todas as fases geram conhecimento base para guiar, neste caso, as políticas urbanas do uso e ocupação do solo. O ponto mais importante do trabalho foi o de apontar os imóveis mais sujeitos a serem alvos dos processo de verticalização, e por consequencia sofrer os efeitos do processo social da gentrificação. O interessante foi que os trabalhos nessa linha focam muito em bairros constrastantes e não em logradouros.
\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
